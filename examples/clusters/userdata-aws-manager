#!/bin/bash

SYNC=${SYNC:-false}
SYSTEM_PRUNE=${SYSTEM_PRUNE:-false}
#SIGNAL_URL=
LABELS=${LABELS:-amp.type.api=true amp.type.route=true amp.type.metrics=true}
#APP_SIGNAL_URL=
CHANNEL=${CHANNEL:-stable}
#PLUGINS=
REGION=${REGION:-us-west-2}
STACK_NAME=${STACK_NAME:-unset}
VPC_ID=${VPC_ID:-unset}
MANAGER_SIZE=${MANAGER_SIZE:-3}
#CLUSTER_SIZE=
DRAIN_MANAGER=${DRAIN_MANAGER:-false}
#OVERLAY_NETWORKS=${OVERLAY_NETWORKS:-core public monit}
#MIRROR_REGISTRIES=
#DOCKER_DEVICE=/dev/sdl
AMPAGENT_VERSION=${APP_VERSION:-latest}
SYSTEMD_DOCKER_OVERRIDE=/etc/systemd/system/docker.service.d/docker.conf
SYSV_DOCKER_DEFAULT=/etc/default/docker

_init_system(){
  systemctl --version >/dev/null 2>&1 && echo systemd && return
  [[ `/sbin/init --version` =~ upstart ]] && echo upstart && return
  echo sysv
}

_install_docker(){
  local _release=$(lsb_release -is)
  local _host
  # on Debian style systems, this checks that docker-ce is installed
  grep -A1 docker-ce /var/lib/dpkg/status | grep -q "installed$"
  if [[ $? -ne 0 ]]; then
    case $CHANNEL in
    stable) _host="get.docker.com" ;;
    edge|beta|test) _host="test.docker.com" ;;
    experimental) _host="experimental.docker.com" ;;
    *) return 1 ;;
    esac
    echo "installing Docker from $_host" >&2
    wget -qO- "https://$_host/" | sh || return 1
  fi
  [[ "x$_release" = "xUbuntu" ]] && usermod -G docker ubuntu 2>/dev/null
  [[ "x$_release" = "xDebian" ]] && usermod -G docker admin  2>/dev/null
  if [[ $(_init_system) = "systemd" ]]; then
    systemctl enable docker.service
    docker version -f {{.Server.Version}} &>/dev/null || systemctl start docker.service
  else
    chkconfig docker on
    docker version -f {{.Server.Version}} &>/dev/null || service docker start
  fi
  docker version >&2
}

# install Docker plugins
# specification of a plugin is in the form PluginName:Version#Options
# plugin specifications should be space separated
_install_plugins(){
  local plugin
  local alias
  local options
  for plugin in $PLUGINS; do
    options="${plugin#*#}"
    [[ "x$options" = "x$plugin" ]] && options="" || options="${options//#/ }"
    plugin="${plugin%%#*}"
    alias=${plugin#store/}
    alias=${alias%:*}
    docker plugin install "$plugin" $options --alias "$alias" --grant-all-permissions # || return 1
  done
  return 0
}

_configure_system_prune(){
  local _cmd="docker system prune -af"
  local _cron_spec="@hourly"

  [[ "x$SYSTEM_PRUNE" != x@(true|yes) ]] && return 0
  echo "configuring crontab for system prune" >&2
  (crontab -l 2>/dev/null; echo "$_cron_spec $_cmd") | crontab -
}

# expose the Docker remote api
_expose_remote_api() {
  case $(_init_system) in
  systemd)
    mkdir -p "$(dirname $SYSTEMD_DOCKER_OVERRIDE)"
    echo "exposing the engine API" >&2
    [[ -f "$SYSTEMD_DOCKER_OVERRIDE" ]] && cp -p "$SYSTEMD_DOCKER_OVERRIDE" "$SYSTEMD_DOCKER_OVERRIDE.bak" && echo "Warning: an existing $SYSTEMD_DOCKER_OVERRIDE was found, it has been backed up" >&2
    cat > "$SYSTEMD_DOCKER_OVERRIDE" <<EOF
[Service]
ExecStart=
ExecStart=/usr/bin/dockerd -H fd:// -H 0.0.0.0:2375 -H unix:///var/run/docker.sock
EOF
    systemctl daemon-reload
  ;;
  sysv)
    cat >> "$SYSV_DOCKER_DEFAULT" <<EOF
DOCKER_OPTS='-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock'
EOF
  ;;
  *)
    echo "not implemented" >&2
    return 1
  ;;
  esac
}

_restart_docker(){
  echo "restarting Docker" >&2
  if [[ $(_init_system) = "systemd" ]]; then
    systemctl restart docker.service
    if [[ $? -ne 0 ]]; then
      echo "daemon.json content:" >&2
      cat /etc/docker/daemon.json >&2
      journalctl -u docker
      return 1
    fi
  else
    service docker restart
    if [[ $? -ne 0 ]]; then
      service docker status
      return 1
    fi
  fi
}

_sanity_check(){
  which aws >/dev/null || return 1
  which jq >/dev/null || return 1
  which base64 >/dev/null || return 1
}

# installs the cfn tools, to be able to signal AWS that the application part of the deployment is done
_install_helpers(){
  [[ "x$SYNC" != "xtrue" ]] && return 0
  [[ -x /usr/local/bin/cfn-signal ]] && return 0
  python -c "import pkg_resources" || curl https://bootstrap.pypa.io/ez_setup.py | python
  curl -sSf https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz | tar xzf -
  (cd aws-cfn-bootstrap-[0-9.]* && python setup.py install) || return 1
  rm -rf aws-cfn-bootstrap-[0-9.]*
  [[ -x /usr/local/bin/cfn-signal ]]
}

_stop_docker(){
  if [[ $(_init_system) = "systemd" ]]; then
    systemctl stop docker.service &>/dev/null
  else
    service docker stop &>/dev/null
  fi
}

_mount_docker_volume(){
  local _mount_point="/var/lib/docker"
  local _device
  local _fstype=xfs
  [[ -z "$1" ]] && return 0
  _device=$(echo $1 | sed 's/\/sd/\/xvd/')
  mkfs.$_fstype $_device || return 1
  echo "$_device    $_mount_point   $_fstype    defaults    0    2" >> /etc/fstab
  rm -rf "$_mount_point"
  mkdir -p "$_mount_point"
  mount "$_mount_point"
}

_system_prerequisites(){
  typeset -i mmc
  local mmcmin=262144
  if mmc=$(sysctl -n vm.max_map_count 2>/dev/null); then
    if [[ $mmc -lt $mmcmin ]]; then
      echo "setting vm.max_map_count to a safe value for elasticsearch"
      sysctl -w vm.max_map_count=262144 || return 1
      echo "vm.max_map_count = 262144" > /etc/sysctl.d/99-amp.conf
    fi
  else
    return 1
  fi
}

# update the docker daemon configuration with the mirror registries
_set_mirror_registries(){
  local _registries="$*"
  local _registry
  local _tmp
  if [[ ! -f /etc/docker/daemon.json ]]; then
    echo "{}" > /etc/docker/daemon.json
  fi
  _tmp=$(mktemp)
  for _registry in $_registries; do
    # Docker pull only accept lower case names,
    # so it's safer to use lower case also in the registry mirror list
    _registry=$(echo "$_registry" | tr '[:upper:]' '[:lower:]'})
    if ! echo "$_registry" | grep -q "://" ; then
      echo "$_registry should contain a scheme, ignore" >&2
      continue
    fi
    echo "adding registry $_registry" >&2
    cat /etc/docker/daemon.json | jq ".[\"registry-mirrors\"] |= .+ [\"$_registry\"]" > "$_tmp" || return 1
    mv "$_tmp" /etc/docker/daemon.json
    if echo "$_registry" | grep -q "http://" ; then
      # declare it as insecure registry
      cat /etc/docker/daemon.json | jq ".[\"insecure-registries\"] |= .+ [\"${_registry}\"]" > "$_tmp" || return 1
      mv "$_tmp" /etc/docker/daemon.json
    fi
  done
}

_set_log_rotation(){
  local _max_size=${1:-10m}
  local _max_file=${2:-3}
  if [[ ! -f /etc/docker/daemon.json ]]; then
    echo "{}" > /etc/docker/daemon.json
  fi
  _tmp=$(mktemp)
  echo "setting log rotation" >&2
  cat /etc/docker/daemon.json | jq ".\"log-opts\".\"max-size\" = \"$_max_size\" | .\"log-opts\".\"max-file\" = \"$_max_file\"" > "$_tmp" || return 1
  mv "$_tmp" /etc/docker/daemon.json
}

_set_metrics_address(){
  local _host=${1:-127.0.0.1}
  local _port=${2:-9323}
  if [[ ! -f /etc/docker/daemon.json ]]; then
    echo "{}" > /etc/docker/daemon.json
  fi
  # multihost bridge is most probably 172.18.0.1
  if [[ "$_host" = "bridge" ]]; then
    _host=$(ip route show dev docker_gwbridge | sed 's/.*src \([0-9\.]*\).*/\1/')
    # when swarm is not enabled yet, this bridge is not set
    [[ -z "$_host" ]] && _host=0.0.0.0
  fi
  _tmp=$(mktemp)
  echo "setting the metrics address ($_host:$_port)" >&2
  cat /etc/docker/daemon.json | jq ".\"metrics-addr\" = \"${_host}:${_port}\" | .experimental = true" > "$_tmp" || return 1
  mv "$_tmp" /etc/docker/daemon.json
}

_wait_for_quorum(){
  local _quorum
  typeset -i _quorum_size=0
  TIMEOUT=300
  SECONDS=0
  echo "waiting for quorum ($MANAGER_SIZE) (will timeout after $TIMEOUT s)" >&2
  if [[ "$MANAGER_SIZE" -eq 1 ]]; then
    # to avoid side effect of ASG launching a new manager and killing the old one once this one is up
    # which would elect the previous manager, soon to be killed
    # if the size of the ASG is 1, then this node should obviously be the leader
    _get_node_ip
    return 0
  fi
  while [[ $_quorum_size -lt $MANAGER_SIZE ]]; do
    _quorum=$(aws ec2 describe-instances --region="${REGION}" --filters "Name=tag:Name,Values=${STACK_NAME}-manager" "Name=instance-state-name,Values=pending,running" "Name=vpc-id,Values=${VPC_ID}" | jq -r '.Reservations[].Instances[].PrivateIpAddress')
    _quorum_size=$(echo $_quorum | wc -w)
    [[ $SECONDS -gt $TIMEOUT ]] && return 1
    sleep 2
  done
  echo "quorum reached in $SECONDS s" >&2
  echo $_quorum
}

# leader election means looking for other members of the group
# and checking if there's already a leader there
# if not, the leader should be elected based on an deterministic algorithm 
_elect_leader(){
  local _local_node=$1
  shift
  local _ips="$*"
  local _docker_version
  local _swarm_status
  local _not_ready=1
  local _timeout=900
  local _leader
  SECONDS=0
  echo "leader election (will timeout after $_timeout s)" >&2
  # wait for all nodes to have a running Docker engine
  while [[ $_not_ready -gt 0 ]]; do
    _not_ready=0
    for _node in $_ips; do
      sleep 1
      [[ "x$_node" = "x$_local_node" ]] && continue
      _docker_version=$(docker -H "$_node:2375" version 2>/dev/null)
      _not_ready=$((_not_ready+$?))
      [[ -z "$_docker_version" ]] && ((_not_ready++))
    done
    [[ $SECONDS -gt $_timeout ]] && return 1
  done
  echo "all manager nodes have an available Docker engine API ($SECONDS s)" >&2
  # look for an existing leader
  for _node in $_ips; do
    _swarm_status=$(docker -H "$_node:2375" node inspect self --format "{{ .ManagerStatus.Leader }}" 2>/dev/null)
    if [[ "x$_swarm_status" = "xtrue" ]]; then
      # we found a leader
      echo "found an established leader manager: $_node" >&2
      echo $_node
      return 0
    fi
  done
  echo "no established leader" >&2
  # arbitrary convention to elect a leader based on the IP
  _leader=$(echo $_ips | tr ' ' '\n' | sort -n | head -1)
  echo "found a new leader: $_leader" >&2
  echo $_leader
}

_swarm_init(){
  local _ip=$1
  echo "initialize the swarm" >&2
  docker swarm init --advertise-addr="$_ip"
}

_get_manager_join_token(){
  local _manager=$1
  local _loop=0
  local _timeout=300
  local _token
  echo "retrieving the swarm manager token (will timeout after $_timeout s)" >&2
  SECONDS=0
  while [[ $SECONDS -lt $_timeout ]]; do
    _token=$(docker -H "$_manager:2375" swarm join-token -q manager)
    if [[ $? -eq 0 && -n "$_token" ]]; then
      echo "manager token obtained ($SECONDS s)" >&2
      echo $_token
      return 0
    fi
    sleep 2
  done
  echo "timeout" >&2
  return 1
}

_create_networks(){
  local _network
  for _network in $*; do
    echo "creating network $_network" >&2
    docker network create -d overlay --attachable $_network || return 1
  done
}

_swarm_cleanup(){
  local _manager=$1
  echo "removing dead nodes from the Swarm" >&2
	# possible node statuses: https://github.com/moby/moby/blob/master/api/types/swarm/node.go#L106-L115
  _down_nodes=$(docker -H "$_manager:2375" node ls --filter "role=manager" --format "{{.Hostname}} {{.Status}}"| grep -i down$ | cut -d' ' -f1)
	# should we also check if corresponding instance is not running/pending in AWS ?
  # like resolve hostname to IP and lookup instance state
  # but assuming if node is down then it is not temporary state and we do not need extra checks
	for _node in $_down_nodes; do
	  echo "removing $_node from the Swarm" >&2
		docker -H "$_manager:2375" node demote $_node
		docker -H "$_manager:2375" node rm $_node
	done 
}

_swarm_join(){
  local _manager=$1
  local _token
  _token=$(_get_manager_join_token "$_manager") || return 1
  echo "joining the Swarm" >&2
  docker swarm join --token "$_token" "$_manager:2377"
}

# add labels on the Swarm node
_label_node(){
  local _self
  local _publicip
  _self=$(docker node inspect self -f '{{.ID}}') || return 1
  _publicip=$(curl -sf 169.254.169.254/latest/meta-data/public-ipv4) || return 1
  echo "applying label PublicIP=$_publicip" >&2
  echo "applying labels amp.type.api and amp.type.route" >&2
  docker node update --label-add "PublicIP=$_publicip" "$_self" >/dev/null || return 1
  for _label in $LABELS; do
    echo "applying label $_label" >&2
    docker node update --label-add "${_label}" "$_self" >/dev/null || return 1
  done
}

_drain_node(){
  local _nodeid
  [[ "x$DRAIN_MANAGER" != "xtrue" ]] && return 0
  echo "drain the node" >&2
  _nodeid=$(docker node inspect self --format '{{.ID}}') || return 1
  docker node update --availability=drain "$_nodeid"
}

_get_node_ip(){
  local _myip
  _myip=$(curl 169.254.169.254/latest/meta-data/local-ipv4)
  echo $_myip
}

_smoke_test(){
  local reachability
  echo "smoke tests...">&2
  SECONDS=0
  while [[ $SECONDS -lt 10 ]]; do
    sleep 1
    docker node ls &>/dev/null || continue
    reachability=$(docker node inspect self -f '{{.ManagerStatus.Reachability}}')
    [[ "x$reachability" = "xreachable" ]] && return 0
  done
  echo "smoke tests fail:" >&2
  docker node ls >&2
  docker node inspect self -f '{{.ManagerStatus.Reachability}}' >&2
  return 1
}

_signal_aws() {
  [[ "x$SYNC" != "xtrue" ]] && return 0
  _url=$1
  [[ -x /usr/local/bin/cfn-signal ]] || return 1
  if [[ -z "$_url" ]]; then
    echo "_signal_aws was called without any URL" >&2
    return 1
  fi
  /usr/local/bin/cfn-signal --stack "${STACK_NAME}" --region "${REGION}" --success true "$_url"
  return 0
}

# wait for all nodes to be up and running (and labeled)
_wait_for_full_swarm() {
  local _timeout=360
  local _timeout_label=60
  local _label
  local _label_prefix="amp.type."
  local _labels="api route metrics mq kv search core user"
  local _expected_label_count
  local _current_labels
  local _current_label_count
  local _size

  if [[ -n "$CLUSTER_SIZE" ]]; then
    echo "Waiting for all nodes to join the swarm" >&2
    # the var can be in the form "N+M+O"
    CLUSTER_SIZE=$((CLUSTER_SIZE))
    SECONDS=0
    while [[ $SECONDS -lt $_timeout ]]; do
      _size=$(docker node ls -q | wc -l)
      if [[ $_size -ge $CLUSTER_SIZE ]]; then
        echo "All nodes have joined after $SECONDS sec" >&2
        break
      fi
      sleep 1
    done
  else
    echo "No knowledge of the swarm size, skipping the wait for the nodes" >&2
  fi

  _expected_label_count=$(echo $_labels | wc -w)
  echo "waiting for all scheduling labels to be defined on the swarm..." >&2
  SECONDS=0
  while [[ $SECONDS -lt $_timeout_label ]]; do
    _current_label_count=0
    _current_labels="$(for n in $(docker node ls -q); do docker node inspect $n --pretty | grep amp.type | sed -e 's/.*\(amp.type.*\) *=.*$/\1/'; done | sort | uniq)"
    for _label in $_labels; do
      echo $_current_labels | grep -q "${_label_prefix}${_label}" && ((++_current_label_count))
    done
    if [[ $_current_label_count -eq $_expected_label_count ]]; then
      echo "All labels were found after $SECONDS sec" >&2
      break
    fi
    sleep 1
  done
  if [[ $_current_label_count -lt $_expected_label_count ]]; then
    echo "label search timed out ($SECONDS sec)" >&2
    return 1
  fi

  
}

_setup() {
  docker run --rm -e VPC_ID="${VPC_ID}" -e STACK_NAME="${STACK_NAME}" -v /var/run/docker:/var/run/docker -v /var/run/docker.sock:/var/run/docker.sock appcelerator/ampagent:${AMPAGENT_VERSION}
}

_sanity_check || exit 1
_install_helpers || exit 1
_stop_docker
_mount_docker_volume $DOCKER_DEVICE || exit 1
_system_prerequisites || exit 1
nodeip=$(_get_node_ip)
_install_docker || exit 1
_install_plugins || exit 1
_expose_remote_api || exit 1
_set_mirror_registries "$MIRROR_REGISTRIES" || exit 1
_set_log_rotation "10m" "3" || exit 1
_set_metrics_address "bridge" "9323" || exit 1
_restart_docker || exit 1
ips=$(_wait_for_quorum) || exit 1
leader="$(_elect_leader $nodeip $ips)" || exit 1
if [[ "x$nodeip" = "x$leader" ]]; then
  _swarm_init "$nodeip" || exit 1
  _create_networks $OVERLAY_NETWORKS || exit 1
else
	_swarm_cleanup "$leader" 
  _swarm_join "$leader" || exit 1
fi
_label_node || exit 1
_drain_node || exit 1
_smoke_test || exit 1
_signal_aws "${SIGNAL_URL}" || exit 1
if [[ "x$nodeip" = "x$leader" && -n "$APP_SIGNAL_URL" ]]; then
  _wait_for_full_swarm || exit 1
  _setup || exit 1
  _signal_aws "${APP_SIGNAL_URL}"
fi
_configure_system_prune || exit 1
