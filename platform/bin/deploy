#!/bin/bash

SUCCESS=0

# run checks (tests); will be set to 1 by -c option
CHECK=0

# This script uses other scripts expected to be in the same directory
# This gets absolute path to script (resolving symlinks)
readonly SP="$(cd "$(dirname "$0")"; pwd -P)"

# dirs
readonly PLATFORMDIR="$(dirname $SP)"
readonly BOOTSTRAPDIR="$PLATFORMDIR/bootstrap"
readonly STACKSDIR="$PLATFORMDIR/stacks"
readonly SECRETSDIR="$PLATFORMDIR/secrets"
readonly TESTSDIR="$PLATFORMDIR/tests"

export PATH="$SP:$BOOTSTRAPDIR:$PATH"

# commands
readonly awscli="docker run --rm -v $HOME/.aws:/root/.aws:ro -v $BOOTSTRAPDIR:$BOOTSTRAPDIR:ro cgswong/aws:latest aws"

# IP range that should have access to the docker remote API
readonly rapi_cidr="$(curl -sf ifconfig.co/ip)/32"
readonly localdomainname="local.atomiq.io"

# global vars
DEPLOYMENT_TARGET=local
CID=
amps=docker
DESTROY=0
STATUS=0

# get and optionally set the target of the deployment: local | dind | aws
deployment_target() {
  [[ ! -z $1 ]] && DEPLOYMENT_TARGET=$1
  echo $DEPLOYMENT_TARGET
}

# create the cluster and echo the cluster id
cluster_create() {
  local _clusterid
  local _status
  local _target
  local _label
  local _label_prefix="amp.type."
  local _labels="mq kv search api metrics route core user"
  _target="$(deployment_target)"
  case $_target in
  local) # for local, enable swarm mode if not already enabled and create the ampnet overlay network
    docker node ls &>/dev/null
    if [[ $? -ne 0 ]]; then
      docker swarm init --advertise-addr 127.0.0.1 &>/dev/null || return 1
    fi
    _clusterid=$(docker node inspect self -f '{{.ID}}') || return 1
    docker network ls | grep -q ampnet
    if [[ $? -ne 0 ]]; then
      echo "create overlay network ampnet" >&2
      docker network create --attachable -d overlay ampnet >/dev/null || return 1
    else
      echo "overlay network ampnet found" >&2
    fi
    # add all service labels for orchestration
    for _label in $_labels; do
      docker node update --label-add "${_label_prefix}${_label}=true" "$_clusterid" >/dev/null
    done
    echo $_clusterid
    ;;
  dind|aws)
    # async
    if [[ $# -eq 0 ]]; then
      bootstrap $BOOTSTRAP_OPTIONS -t "$_target" -f
    else
      bootstrap $BOOTSTRAP_OPTIONS -t "$_target" -fi $1
    fi ;;
  esac
}

# destroy the cluster
cluster_destroy() {
  local _target
  local _code=1
  local _vols
  set_deployment_variables
  _target="$(deployment_target)"
  case $_target in
  dind|aws)
    bootstrap -t $_target -di $1 ;;
  local)
    docker stack rm amp
    # wait for containers to be removed
    SECONDS=0
    while [[ $_code -ne 0 ]]; do
      sleep 2
      docker volume ls -q | grep "^amp_" | xargs docker volume rm 2>/dev/null
      _code=$?
      [[ $SECONDS -gt 25 ]] && break
    done
    _vols=$(docker volume ls -q | grep "^amp_")
    [[ -n "$_vols" ]] && echo "docker volumes $_vols has not been removed, you should do it manually"
    return 0
    ;;
  esac
}

# status of cluster, expects the cluster id as argument
# exit 0 means healthy
cluster_status() {
  local _clusterid=$1
  local _status
  local _target
  _target=$(deployment_target)
  case $_target in
  local)
    if [[ -n "$_clusterid" ]]; then
      docker node ls -q | grep $_clusterid &>/dev/null
    else
      docker node ls -q &>/dev/null
    fi
    ;;
  dind|aws)
    bootstrap -t $_target -s $_clusterid >/dev/null 2>&1 ;;
  esac
}

# size of cluster, expects the cluster id as argument
cluster_nodecount() {
  local _clusterid=$1
  local _target
  local _count
  _target=$(deployment_target)
  case $_target in
  local) # single manager node
    echo 1
    ;;
  dind|aws)
    _count=$(bootstrap -t $_target -l $_clusterid | wc -l)
    if [[ $_count -gt 0 ]]; then
      echo $_count
      return 0
    fi
    echo "node count failed" >&2
    bootstrap -t $_target -l $_clusterid >&2
    return 1
    ;;
  *)
    echo "unknown deployment target ($_target)" >&2
    return 1 ;;
  esac
}

# worker count in the cluster
cluster_workercount() {
  local _clusterid=$1
  local _target
  local _count
  _target=$(deployment_target)
  case $_target in
  local) # single manager node
    echo 0
    ;;
  dind|aws)
    _count=$(bootstrap -t $_target -l $_clusterid | grep -c worker)
    if [[ $_count -gt 0 ]]; then
      echo $_count
      return 0
    fi
    echo "node count failed" >&2
    bootstrap -t $_target -l $_clusterid >&2
    return 1
    ;;
  *)
    echo "unknown deployment target ($_target)" >&2
    return 1 ;;
  esac
}

# creates a amp-stacks volume by sending the stacks to the host in a build context
create_amp_stacks_volume() {
  local builddir=$(mktemp -d)
  local dockerfile=$builddir/Dockerfile
  local image=amp-stacks-builder:local
  cat > $dockerfile << EOF
FROM alpine:3.5
COPY stacks /stacks
VOLUME /stacks
CMD ["true"]
EOF
  cp -pr $SP/../stacks $builddir/stacks
  docker build -t $image $builddir >/dev/null
  rm -rf $builddir
  docker run --rm -v amp-stacks:/stacks $image
  docker image rm $image > /dev/null
}

# creates a amp-secrets volume by sending the local secrets to the host in a build context
create_amp_secrets_volume() {
  local builddir=$(mktemp -d)
  local dockerfile=$builddir/Dockerfile
  local image=amp-secrets-builder:local
  cat > $dockerfile << EOF
FROM alpine:3.5
COPY secrets /secrets
VOLUME /secrets
CMD ["true"]
EOF
  mkdir -p "$SECRETSDIR"
  cp -pr "$SECRETSDIR" "$builddir/secrets"
  docker build -t $image $builddir >/dev/null
  rm -rf $builddir
  docker run --rm -v amp-secrets:/secrets $image
  docker image rm $image > /dev/null
}

# sets hosts for Docker remote API and for the Docker registry
# depending on the deployment target
set_deployment_variables(){
  local _manager
  case $(deployment_target) in
  local)
    stacks_path="$STACKSDIR"
    secrets_path="$SECRETSDIR"
    amps="docker"
    domainname=$localdomainname
    return
    ;;
  dind)
    dockerhost=m1
    registryhost=127.0.0.1
    create_amp_stacks_volume
    create_amp_secrets_volume
    _manager=$(docker exec m1 docker node inspect self -f '{{.Status.Addr}}')
    amps="docker run -t --rm --network=hostnet -e MANAGER_HOST=$_manager -e TAG=$TAG -e REGISTRATION=$REGISTRATION -e NOTIFICATIONS=$NOTIFICATIONS -v amp-secrets:/secrets -v amp-stacks:/stacks docker --host=$dockerhost"
    stacks_path=/stacks
    secrets_path=/secrets
    domainname=$localdomainname
    export DOCKERHOST=$dockerhost
    ;;
  aws)
    local awscf="$awscli --profile ${PROFILE:-default} --region ${REGION:-us-west-2} cloudformation"
    local _clusterid
    local _publicip
    _clusterid="$CID"
    echo "$CID" | grep -q "/" && _clusterid="$(echo $CID | awk -F/ '{print $2}')"
    # todo: use a secured remote API
    dockerhost=$($awscf describe-stacks --stack-name $_clusterid --query 'Stacks[0].Outputs[?OutputKey==`PublicManagerHost`].OutputValue' --output text) || exit 1
    _manager=$($awscf describe-stacks --stack-name $_clusterid --query 'Stacks[0].Outputs[?OutputKey==`PrivateManagerHost`].OutputValue' --output text) || exit 1
    # if the DNS name point to several engines, we need a single one to avoid strange CLI issues (run = 2 calls, create + start)
    _publicip=$(docker -H "$dockerhost" node inspect self -f '{{.Spec.Labels.PublicIP}}')
    [[ "$_publicip" = "<no value>" ]] && _publicip=""
    registryhost=$($awscf describe-stacks --stack-name $_clusterid --query 'Stacks[0].Outputs[?OutputKey==`MirrorRegistries`].OutputValue' --output text) || exit 1
    # if a single registry is defined on this cluster, we'll push images on it
    # else, we'll skip the image push
    echo "$registryhost" | grep -q " " && registryhost=""
    amps="docker -H ${_publicip:-$dockerhost}"
    stacks_path=$STACKSDIR
    secrets_path=$SECRETSDIR
    domainname=$DOMAIN
    # variable used in sub scripts
    export MANAGER_HOST=$_manager
    export DOCKERHOST=${_publicip:-$dockerhost}
    ;;
  esac

  registryurl=$(echo $registryhost | cut -d, -f1)
  # if no scheme, add the default port
  if echo $registryurl | grep -qv "://" && [[ -n "$registryurl" ]]; then registryurl=$registryurl:5000; fi
  echo "Docker host = $dockerhost"
  echo "Docker registry = $registryurl"
}

checkexit() {
  ec=$?
  (( $ec != 0 )) && printf "$@ (exit code: $ec)\n" && exit $ec
}

cleanup() {
  [[ $DESTROY -eq 1 ]] && exit 0
  [[ $STATUS -eq 1 ]] && exit 0
  docker volume rm amp-stacks &>/dev/null
  docker volume rm amp-secrets &>/dev/null
  [[ SUCCESS -ne 1 && ! -z $CID && $(deployment_target) = "dind" ]] && echo "clean up" && bootstrap -p local -d -i $CID
  [[ SUCCESS -ne 1 && ! -z $CID && $(deployment_target) = "local" ]] && echo "clean up" && cluster_destroy $CID
}

ok() {
  echo ok $1
}

pushimage() {
  echo "push image: $1/$2"
  docker tag $2 $1/$2
  checkexit "error tagging image"
  docker push $1/$2
  checkexit "error pushing image"
  ok
}

deploystack() {
  echo "deploy $1 => $2"
  $amps stack deploy -c $stacks_path/$1 $2
  checkexit "error deploying stack"
  ok
}

# can only use this once the swarm is ready
lookup() {
  [[ -z $amps ]] && echo "error to use lookup before swarm is created" && return 1
  $amps run --rm --network=ampnet appcelerator/alpine:3.5.2 nslookup $1
}

# can only use this once the swarm is ready
kurl() {
  [[ -z $amps ]] && echo "error to use kurl before swarm is created" && return 1
  $amps run --rm --network=ampnet appcelerator/alpine:3.5.2 curl -L -s -o /dev/null -w '%{http_code}\n' $1
}

# pushes the amplifier configuration in a secret
# TODO: empty for now
prepare_amplifier_configuration(){
  local _conf
  local cid
  $amps secret ls | grep -q "amplifier_yml" && return 0
  _conf="$SECRETSDIR/amplifier.yml"
  if [[ ! -f "$_conf" ]]; then
    local supasswd
    mkdir -p "$SECRETSDIR"
    echo "JWTSecretKey: "$(docker run --rm alpine sh -c '< /dev/urandom tr -dc [:alnum:] | head -c${1:-128}') > "$_conf"
    supasswd=$(docker run --rm alpine sh -c '< /dev/urandom tr -dc [:alnum:] | head -c${1:-32}')
    echo "SUPassword: " "$supasswd" >> "$_conf"
    echo "The super user password for this deployment is: $supasswd"
  else
    echo "using existing configuration for the amplifier_yml secret" >&2
  fi
  # copy the configuration in the amp-secrets volume
  cid=$(docker run -d --rm -v amp-secrets:/secrets alpine:3.5 sleep 15)
  if [[ $? -ne 0 || -z "$cid" ]]; then return 1; fi
  docker cp "$_conf" $cid:/secrets/
  docker kill "$cid" >/dev/null 2>&1
  $amps secret create "amplifier_yml" "$secrets_path/$(basename $_conf)" >/dev/null && echo "secret amplifier_yml successfully created" >&2
}

prepare_prometheus_configuration(){
  local _conf
  local cid
  $amps secret ls | grep -q "prometheus_alerts_rules" && return 0
  _conf="$SECRETSDIR/prometheus_alerts.rules"
  if [[ ! -f "$_conf" ]]; then
    mkdir -p "$SECRETSDIR"
    echo > "$_conf"
  else
    echo "using existing configuration for the prometheus_alerts_rules secret" >&2
  fi
  # copy the configuration in the amp-secrets volume
  cid=$(docker run -d --rm -v amp-secrets:/secrets alpine:3.5 sleep 15)
  if [[ $? -ne 0 || -z "$cid" ]]; then return 1; fi
  docker cp "$_conf" $cid:/secrets/
  docker kill "$cid" >/dev/null 2>&1
  $amps secret create "prometheus_alerts_rules" "$secrets_path/$(basename $_conf)" >/dev/null && echo "secret prometheus_alerts_rules successfully created" >&2
}

prepare_alertmanager_configuration(){
  local _conf
  local cid
  $amps secret ls | grep -q "alertmanager_yml" && return 0
  _conf="$SECRETSDIR/alertmanager.yml"
  if [[ ! -f "$_conf" ]]; then
    mkdir -p "$SECRETSDIR"
    cat > "$_conf" << EOF
global:
  smtp_smarthost: 'localhost:25'
  smtp_from: 'alertmanager@example.org'
route:
  receiver: none
receivers:
- name: 'none'
  email_configs:
  - to: 'null@localhost'
EOF
  else
    echo "using existing configuration for the alertmanager_yml secret" >&2
  fi
  # copy the configuration in the amp-secrets volume
  cid=$(docker run -d --rm -v amp-secrets:/secrets alpine:3.5 sleep 15)
  if [[ $? -ne 0 || -z "$cid" ]]; then return 1; fi
  docker cp "$_conf" $cid:/secrets/
  docker kill "$cid" >/dev/null 2>&1
  $amps secret create "alertmanager_yml" "$secrets_path/$(basename $_conf)" >/dev/null && echo "secret alertmanager_yml successfully created" >&2
}
# pushes certificates in a Docker secret, ready to use by services in stack files
# for local/dind bootstrap, a self signed certificate is created
# for cloud bootstrap, a valid certificate should be provided
# it has to be in the stacks folder, to allow access to the Docker client
prepare_certificates() {
  if [[ $# -ne 1 ]]; then
    return 1
  fi
  $amps secret ls | grep -q "certificate_atomiq" && return 0

  local name=$1
  local certfile="$SECRETSDIR/$name.pem"

  mkdir -p "$SECRETSDIR"
  case $(deployment_target) in
  local|dind)
    mv "$(mkcert)" "$certfile" ;;
  esac
  if [[ ! -f "$certfile" ]]; then
    # TODO use certbot
    echo "can't find certificate $certfile" >&2
    return 1
  fi
  # copy the certificate in the amp-secrets volume
  cid=$(docker run -d --rm -v amp-secrets:/secrets alpine:3.5 sleep 15)
  if [[ $? -ne 0 || -z "$cid" ]]; then return 1; fi
  docker cp "$certfile" $cid:/secrets/$name.pem
  docker kill "$cid" >/dev/null 2>&1
  echo "creating the certificate secret"
  $amps secret create "certificate_atomiq" "$secrets_path/$name.pem" >/dev/null && echo "secret certificate_atomiq successfully created" >&2
}

# process the command line options and arguments
parse_cmd() {
  while getopts ":w:m:t:l:T:c:r:n:p:g:dsD:" opt; do
    case $opt in
    w|m|t|l) # just pass it to the bootstrap script
      BOOTSTRAP_OPTIONS="$BOOTSTRAP_OPTIONS -${opt} $OPTARG"
      ;;
    s) STATUS=1
       if [[ -z "$CID" ]]; then
         CID="$(docker node inspect self -f '{{.ID}}')"
         if [[ $? -ne 0 ]]; then
           echo "you should pass a cluster id as argument" >&2
           exit 1
         fi
       fi
      ;;
    d) DESTROY=1
       if [[ -z "$CID" ]]; then
         CID="$(docker node inspect self -f '{{.ID}}')"
         if [[ $? -ne 0 ]]; then
           echo "you should pass a cluster id as argument" >&2
           exit 1
         fi
       fi
      ;;
    T) # tag for images to deploy
      export TAG=$OPTARG
      ;;
    r) # registration policy
      export REGISTRATION=$OPTARG
      ;;
    n) # notifications
      export NOTIFICATIONS=$OPTARG
      ;;
    D) # domain for cluster deployment
      BOOTSTRAP_OPTIONS="$BOOTSTRAP_OPTIONS -${opt} $OPTARG"
      DOMAIN=$OPTARG
      if [[ ! -f $SECRETSDIR/${DOMAIN}.pem ]]; then
        echo "can't find ${DOMAIN}.pem in $SECRETSDIR, abort" >&2
        exit 1
      fi
      ;;
    c)
      CHECK=1
      ;;
    p) # provider
      deployment_target $OPTARG >/dev/null
      ;;
    g) # region for cluster deployment
      REGION=$OPTARG
      export REGION
      ;;
    esac
  done
  shift "$((OPTIND-1))"

  CID=$1
}

bootstrap_cluster() {
  if [[ -z "$CID" ]]; then
    echo "bootstrapping cluster on $DEPLOYMENT_TARGET"
    CID=$(cluster_create)
    checkexit "bootstrap failed"
    [[ -n "$CID" ]] && echo $CID
    checkexit "no clusterid"
  else
    cluster_status $CID || cluster_create $CID
    checkexit "bootstrap failed"
  fi

  set_deployment_variables

  if [[ "$(deployment_target)" != "local" ]]; then
    echo "wait for cluster"
    clustercheck -t 150 -p $(deployment_target) $CID
    checkexit "cluster timed out"
    ok
  fi

  typeset -i nodecount
  nodecount=$(cluster_nodecount $CID)
  checkexit "failed to count cluster nodes"
  echo "cluster size is $nodecount"

  echo "wait for swarm mode"
  swarmcheck -t 300 -c $nodecount
  checkexit "swarm mode timed out"
  ok

  if [[ -n "$registryurl" ]]; then
    echo "wait for registry"
    curlcheck "${registryurl}/v2/" 200 180
    checkexit "registry timed out"
    ok
  fi

  if [[ -n "$registryurl" && "x$TAG" = "xlocal" ]]; then
    echo "push images to cluster"
    for image in amplifier gateway ampbeat agent; do
      pushimage "${registryurl}" "appcelerator/${image}:${TAG:-local}"
    done
  else
    echo "image push to cluster is ignored (tag=${TAG:-latest})"
  fi
}

deploy_stacks() {
  local maxwait=300 # should be less than 10 minutes (600s) so not to exceed travis deadline
  local _workercount

  if [[ "$(deployment_target)" = "local" ]]; then
    # force all placement constraints to deploy to a single manager
    export NODE_ROLE=manager
  fi

  echo "deploy amp monitoring stack to cluster - stage 1"
  _workercount=$(cluster_workercount $CID) || return 1
  [[ $_workercount -le 9 ]] && deploystack ampmon-single.1.stack.yml amp || deploystack ampmon-cluster.1.stack.yml amp
  echo "wait for all amp monitoring stage 1 stack service replicas to be running"

  servicescheck $maxwait
  checkexit "amp monitoring stage 1 service replica checks timed out"
  ok

  echo "deploy amp monitoring stack to cluster - stage 2"
  deploystack ampmon.2.stack.yml amp
  echo "wait for all amp monitoring stage 2 service replicas to be running ($maxwait sec)"
  servicescheck $maxwait
  checkexit "amp monitoring stage 2 service replica checks timed out"
  ok

  prepare_prometheus_configuration
  checkexit "secret creation for prometheus failed"
  prepare_alertmanager_configuration
  checkexit "secret creation for alertmanager failed"

  echo "deploy amp monitoring stack to cluster - stage 3"
  deploystack ampmon.3.stack.yml amp
  echo "wait for all amp monitoring stage 3 service replicas to be running ($maxwait sec)"
  servicescheck $maxwait
  checkexit "amp monitoring stage 3 service replica checks timed out"
  ok

  echo "deploy portal stack to cluster"
  deploystack portal.stack.yml amp
  echo "wait for all portal service replicas to be running ($maxwait sec)"
  servicescheck $maxwait
  checkexit "portal service replica checks timed out"
  ok

  prepare_amplifier_configuration
  checkexit "secret creation for amplifier failed"
  echo "deploy amp stack to cluster"
  deploystack amp.stack.yml amp
  echo "wait for all amp service replicas to be running ($maxwait sec)"
  servicescheck $maxwait
  checkexit "amp service replica checks timed out"
  ok

  prepare_certificates $domainname
  if [[ $? -eq 0 ]]; then
    echo "deploy amp proxy stack to cluster"
    deploystack ampproxy.stack.yml amp
    echo "wait for all amp proxy service replicas to be running ($maxwait sec)"
    servicescheck $maxwait
    checkexit "amp proxy service replica checks timed out"
    ok
  else
    echo "won't deploy the proxy stack, there's no certificate"
  fi
}

smoke_tests() {
  (( $CHECK == 0 )) && return

  #####
  # following checks need to move to $TESTSDIR
  #
  servicescheck 0
  checkexit "service replica check failed"
  ok

  echo
  $amps service ls
  echo

  # sanity service lookup and ping checks after starting monitoring stack
  echo "test nats availability"
  lookup nats >/dev/null
  checkexit "service lookup check failed: nats"
  ok "service lookup check succeeded: nats"
  kurl nats:8222
  checkexit "service ping check failed: nats"
  ok "service ping check succeeded: nats"

  echo "test elasticsearch availability"
  lookup elasticsearch >/dev/null
  checkexit "service lookup check failed: elasticsearch"
  ok "service lookup check succeeded: elasticsearch"
  kurl elasticsearch:9200
  checkexit "service ping check failed: elasticsearch"
  ok "service ping check succeeded: elasticsearch"
  #
  #
  #####

  # run additional smoke tests if CHECK > 1
  if (( $CHECK > 1 )); then
    $PLATFORMDIR/testing/testrunner $TESTSDIR
    checkexit "smoke tests failed"
  fi

  ok "smoke tests passed"
}

main() {
  parse_cmd $@
  if [[ $STATUS -eq 1 ]]; then
    cluster_status $CID
    return $?
  fi
  if [[ $DESTROY -eq 1 ]]; then
    cluster_destroy $CID
    return $?
  fi
  bootstrap_cluster
  deploy_stacks
  smoke_tests

  # set SUCCESS for EXIT trap
  SUCCESS=1
  printf "\nCluster status: healthy\n$CID"
}

trap cleanup EXIT
main $@
