#!/bin/bash

REGION=${REGION:-us-west-2}
STACK_NAME=${STACK_NAME:-unset}
VPC_ID=${VPC_ID:-unset}
BASE_URL=${BASE_URL:-unset}
MANAGER_SIZE=${MANAGER_SIZE:-3}
ENV_FILE=${ENV_FILE:-/tmp/env.ikt}
DRAIN_MANAGER=${DRAIN_MANAGER:-false}
OVERLAY_NETWORKS=${OVERLAY_NETWORKS:-ampnet}

_install_docker(){
  wget -qO- https://get.docker.com/ | sh || return 1
  usermod -G docker ubuntu
  systemctl enable docker.service
  systemctl start docker.service
}

# expose the Docker remote api
_expose_remote_api() {
  mkdir -p /etc/systemd/system/docker.service.d
  echo "exposing the engine API" >&2
  cat > /etc/systemd/system/docker.service.d/docker.conf <<EOF
[Service]
ExecStart=
ExecStart=/usr/bin/dockerd -H fd:// -H 0.0.0.0:2375 -H unix:///var/run/docker.sock --experimental
EOF
  systemctl daemon-reload
}

_restart_docker(){
  echo "restarting Docker" >&2
  systemctl restart docker.service
}

_sanity_check(){
  which aws >/dev/null || return 1
  which jq >/dev/null || return 1
  which base64 >/dev/null || return 1
}

_system_prerequisites(){
  typeset -i mmc
  local mmcmin=262144
  if mmc=$(sysctl -n vm.max_map_count 2>/dev/null); then
    if [[ $mmc -lt $mmcmin ]]; then
      echo "setting vm.max_map_count to a safe value for elasticsearch"
      sysctl -w vm.max_map_count=262144 || return 1
      echo "vm.max_map_count = 262144" > /etc/sysctl.d/99-amp.conf
    fi
  else
    return 1
  fi
}

# update the docker daemon configuration with the mirror registries
_set_mirror_registries(){
  local _registries="$*"
  local _registry
  local _tmp
  if [[ ! -f /etc/docker/daemon.json ]]; then
    echo "{}" > /etc/docker/daemon.json
  fi
  _tmp=$(mktemp)
  for _registry in $_registries; do
    if ! echo "$_registry" | grep -q "://" ; then
      echo "$_registry should contain a scheme, ignore" >&2
      continue
    fi
    echo "adding registry $_registry" >&2
    cat /etc/docker/daemon.json | jq ".[\"registry-mirrors\"] |= .+ [\"$_registry\"]" > "$_tmp"
    mv "$_tmp" /etc/docker/daemon.json
  done
}

_wait_for_quorum(){
  local _quorum
  typeset -i _quorum_size=0
  TIMEOUT=300
  SECONDS=0
  echo "waiting for quorum ($MANAGER_SIZE)" >&2
  while [[ $_quorum_size -lt $MANAGER_SIZE ]]; do
    _quorum=$(aws ec2 describe-instances --region="${REGION}" --filters "Name=tag:Name,Values=${STACK_NAME}-manager" "Name=instance-state-name,Values=pending,running" "Name=vpc-id,Values=${VPC_ID}" | jq -r '.Reservations[].Instances[].PrivateIpAddress')
    _quorum_size=$(echo $_quorum | wc -w)
    [[ $SECONDS -gt $TIMEOUT ]] && return 1
    sleep 2
  done
  echo $_quorum
}

# leader election means looking for other members of the group
# and checking if there's already a leader there
# if not, the leader should be elected based on an deterministic algorithm 
_elect_leader(){
  local _local_node=$1
  shift
  local _ips="$*"
  local _docker_version
  local _swarm_status
  local _not_ready=1
  local _timeout=300
  local _leader
  SECONDS=0
  echo "leader election" >&2
  # wait for all nodes to have a running Docker engine
  while [[ $_not_ready -gt 0 ]]; do
    _not_ready=0
    for _node in $_ips; do
      sleep 1
      [[ "x$_node" = "x$_local_node" ]] && continue
      _docker_version=$(docker -H "$_node:2375" version 2>/dev/null)
      _not_ready=$((_not_ready+$?))
      [[ -z "$_docker_version" ]] && ((_not_ready++))
    done
    [[ $SECONDS -gt $_timeout ]] && return 1
  done
  echo "all manager nodes have an available Docker engine API" >&2
  # look for an existing leader
  for _node in $_ips; do
    _swarm_status=$(docker -H "$_node:2375" node inspect self --format "{{ .ManagerStatus.Leader }}" 2>/dev/null)
    if [[ "x$_swarm_status" = "xtrue" ]]; then
      # we found a leader
      echo "found an established leader manager: $_node" >&2
      echo $_node
      return 0
    fi
  done
  echo "no established leader" >&2
  # arbitrary convention to elect a leader based on the IP
  _leader=$(echo $_ips | tr ' ' '\n' | sort -n | head -1)
  echo "found a new leader: $_leader" >&2
  echo $_leader
}

_swarm_init(){
  local _ip=$1
  echo "initialize the swarm" >&2
  docker swarm init --advertise-addr="$_ip"
}

_get_manager_join_token(){
  local _manager=$1
  local _loop=0
  local _timeout=300
  local _token
  echo "retrieving the swarm manager token" >&2
  SECONDS=0
  while [[ $SECONDS -lt $_timeout ]]; do
    _token=$(docker -H "$_manager:2375" swarm join-token -q manager)
    if [[ $? -eq 0 && -n "$_token" ]]; then
      echo "manager token obtained" >&2
      echo $_token
      return 0
    fi
    sleep 2
  done
  echo "timeout" >&2
  return 1
}

_create_networks(){
  local _network
  for _network in $*; do
    echo "creating network $_network" >&2
    docker network create -d overlay --attachable $_network || return 1
  done
}

_swarm_join(){
  local _manager=$1
  local _token
  _token=$(_get_manager_join_token "$_manager") || return 1
  echo "joining the Swarm" >&2
  docker swarm join --token "$_token" "$_manager:2377"
}

# add labels on the Swarm node
_label_node(){
  local _self
  local _publicip
  _self=$(docker node inspect self -f '{{.ID}}') || return 1
  _publicip=$(curl -sf 169.254.169.254/latest/meta-data/public-ipv4) || return 1
  docker node update --label-add "PublicIP=$_publicip" "$_self"
}

_drain_node(){
  local _nodeid
  [[ "x$DRAIN_MANAGER" != "xtrue" ]] && return 0
  echo "drain the node" >&2
  _nodeid=$(docker node inspect self --format '{{.ID}}') || return 1
  docker node update --availability=drain "$_nodeid"
}

_mk_infrakit_plugins_config() {
  local _file
  local _base64decode
  local _b64config="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"
  _file=$(mktemp)
  # base64 behaves differently on different OSes
  base64 --version >/dev/null 2>&1 && _base64decode="base64 -d" || _base64decode="base64 -D"
  echo "$_b64config" | $_base64decode > "$_file"
  echo $_file
}

_run_infrakit(){
  local _image="appcelerator/infrakit"
  local _image_version="0.4.0"
  local _container_name="infrakit"
  local _volume_name="infrakit"
  local _infrakit_log_level=4
  local _plugins_cfg
  local _instance_plugin=instance-aws
  local _mux_port=24864
  local _cid

  _plugins_cfg=$(_mk_infrakit_plugins_config)
  # create a volume for infrakit
  docker volume inspect $_volume_name 2>/dev/null || docker volume create $_volume_name || return 1
  # run the infrakit container with a listener for remote connection
  docker run -d -v "$_volume_name:/infrakit" -v "$_plugins_cfg:/infrakit/plugins.json" \
        -v /var/run/docker.sock:/var/run/docker.sock \
	-e INFRAKIT_HOME=/infrakit -e INFRAKIT_PLUGINS_DIR=/infrakit/plugins -e INFRAKIT_LOG_LEVEL=$_infrakit_log_level \
	-p ${_mux_port}:24864 \
	--name "$_container_name" "${_image}:${_image_version}" \
	infrakit util mux --log $_infrakit_log_level
  # pass the custom configuration to the infrakit container
  docker cp /etc/infrakit.conf infrakit:/infrakit/env.ikt
  # run the plugins
  docker exec -d infrakit \
	infrakit plugin start --exec os --log "$_infrakit_log_level" --config-url /infrakit/plugins.json \
	manager-swarm group-stateless "$_instance_plugin" flavor-combo flavor-vanilla flavor-swarm
  # if the infrakit container is not running anymore, return an error
  sleep 1
  _cid=$(docker ps -f name=infrakit -q)
  [[ -n "$_cid" ]]
}

_get_node_ip(){
  local _myip
  _myip=$(curl 169.254.169.254/latest/meta-data/local-ipv4)
  echo $_myip
}


_sanity_check || exit 1
_system_prerequisites || exit 1
nodeip=$(_get_node_ip)
_install_docker || exit 1
_expose_remote_api || exit 1
_set_mirror_registries "$MIRROR_REGISTRIES" || exit 1
_restart_docker || exit 1
ips=$(_wait_for_quorum) || exit 1
leader="$(_elect_leader $nodeip $ips)" || exit 1
if [[ "x$nodeip" = "x$leader" ]]; then
  _swarm_init "$nodeip" || exit 1
  _create_networks $OVERLAY_NETWORKS || exit 1
else
  _swarm_join "$leader" || exit 1
fi
_label_node || exit 1
_drain_node || exit 1
_run_infrakit
